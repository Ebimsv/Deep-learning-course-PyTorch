{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import torchvision  \n",
    "import torchvision.transforms as transforms  \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define a Residual Block (Basic Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the context of ResNet (Residual Networks), the terms Basic Block and Residual Block can be considered synonymous, but they might refer to slightly different concepts depending on the specific architecture and context. Below, I will explain this in more detail.\n",
    "\n",
    "# **What is a Residual Block?**\n",
    "A Residual Block is a neural network layer component introduced in the ResNet architecture to help train very deep networks more effectively. The primary innovation of a Residual Block is the introduction of skip connections (or shortcut connections), which allow gradients to flow more easily during backpropagation.\n",
    "\n",
    "## **Structure of a Residual Block**\n",
    "A typical Residual Block consists of:\n",
    "\n",
    "1. **Two Convolutional Layers**:\n",
    "\n",
    "    - Each layer is usually followed by a batch normalization layer and a non-linear activation function (ReLU).\n",
    "    - If the input and output dimensions are the same, the outputs from the convolutional layers are added to the original input (the shortcut connection) before passing through a final activation function.\n",
    "\n",
    "2. **Shortcut Connection**:\n",
    "\n",
    "    - This connection skips the two convolutional layers and provides the original input to the output of the block.\n",
    "    - This can be simply an identity connection, but if the dimensions do not match (for example, when downsampling), a linear layer (1x1 convolution) may be used to adjust the dimensions before adding it to the output.\n",
    "\n",
    "### **Mathematical Representation**\n",
    "For an input x to the block, the output y can be formulated as:\n",
    "\n",
    "        y = F(x) + x\n",
    "\n",
    "Where F(x) represents the nonlinear transformation (the two convolutional layers, batch normalization, and activation function).\n",
    "\n",
    "## **What is a Basic Block?**\n",
    "The Basic Block is a specific implementation of a residual block used in ResNet architectures. For example, in ResNet-18 and ResNet-34, the Basic Block typically has:\n",
    "\n",
    "- 2 convolutional layers, each followed by batch normalization and a ReLU activation.\n",
    "- A skip connection directly connecting the input to the output.\n",
    "\n",
    "## **Differences in Variants**\n",
    "1. **Basic Block**: Commonly used in the ResNet architectures with fewer parameters. It typically does not have a downsampling path; both the input and output have the same dimensions.\n",
    "\n",
    "2. **Bottleneck Block**: In deeper architectures like ResNet-50 and ResNet-101, a Bottleneck Block is used. It consists of three convolutional layers instead of two. The first layer reduces dimensions (1x1 convolution), the second layer performs the main convolution (3x3), and the third layer restores dimensions (1x1 convolution). The intention is to reduce the computational cost while maintaining the expressiveness of the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ResNet, a basic block consists of two convolutional layers with a skip connection (identity mapping). \n",
    "# Here, we'll define the BasicBlock class:\n",
    "\n",
    "class BasicBlock(nn.Module):  \n",
    "    expansion = 1  \n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):  \n",
    "        super(BasicBlock, self).__init__()  \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)  \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)  \n",
    "        self.relu = nn.ReLU(inplace=True)  \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)  \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)  \n",
    "        self.downsample = downsample  \n",
    "\n",
    "    def forward(self, x):  \n",
    "        identity = x  \n",
    "        \n",
    "        out = self.conv1(x)  \n",
    "        out = self.bn1(out)  \n",
    "        out = self.relu(out)  \n",
    "\n",
    "        out = self.conv2(out)  \n",
    "        out = self.bn2(out)  \n",
    "\n",
    "        if self.downsample is not None:  \n",
    "            identity = self.downsample(x)  \n",
    "\n",
    "        out += identity  \n",
    "        out = self.relu(out)  \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define the ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the ResNet class, which will use the BasicBlock to build the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):  \n",
    "    def __init__(self, block, layers, num_classes=10):  \n",
    "        super(ResNet, self).__init__()  \n",
    "        self.in_channels = 64  \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)  \n",
    "        self.bn1 = nn.BatchNorm2d(64)  \n",
    "        self.relu = nn.ReLU(inplace=True)  \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  \n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])  \n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)  \n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)  \n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)  \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)  \n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):  \n",
    "        downsample = None  \n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:  \n",
    "            downsample = nn.Sequential(  \n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),  \n",
    "                nn.BatchNorm2d(out_channels * block.expansion),  \n",
    "            )  \n",
    "\n",
    "        layers = []  \n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))  \n",
    "        self.in_channels = out_channels * block.expansion  \n",
    "        for _ in range(1, blocks):  \n",
    "            layers.append(block(self.in_channels, out_channels))  \n",
    "\n",
    "        return nn.Sequential(*layers)  \n",
    "\n",
    "    def forward(self, x):  \n",
    "        x = self.conv1(x)  \n",
    "        x = self.bn1(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.maxpool(x)  \n",
    "\n",
    "        x = self.layer1(x)  \n",
    "        x = self.layer2(x)  \n",
    "        x = self.layer3(x)  \n",
    "        x = self.layer4(x)  \n",
    "\n",
    "        x = self.avgpool(x)  \n",
    "        x = torch.flatten(x, 1)  \n",
    "        x = self.fc(x)  \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Instantiate the Model\n",
    "\n",
    "Now create an instance of the ResNet model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18():  \n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Prepare CIFAR-10 Dataset  \n",
    "Now, we have to load and preprocess the CIFAR-10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing  \n",
    "transform = transforms.Compose([  \n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  \n",
    "])  \n",
    "\n",
    "# Load CIFAR-10 dataset  \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)  \n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)  \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)  \n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Define Training Parameters\n",
    "Set device, loss function, optimizer, and other configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "model = resnet18().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Train the Model\n",
    "Now, we train the model. Here's how you can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  \n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  \n",
    "    running_loss = 0.0  \n",
    "    for inputs, labels in trainloader:  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        running_loss += loss.item()  \n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Evaluate the Model\n",
    "After training, evaluate the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  \n",
    "correct = 0  \n",
    "total = 0  \n",
    "\n",
    "with torch.no_grad():  \n",
    "    for inputs, labels in testloader:  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)  \n",
    "        outputs = model(inputs)  \n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        total += labels.size(0)  \n",
    "        correct += (predicted == labels).sum().item()  \n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
