{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple CNN Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN class\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Shape Explanation**\n",
    "\n",
    "1. **Input Shape**: If the input is a single image of size 32x32 with 3 color channels, the shape would be (1, 3, 32, 32).\n",
    "\n",
    "2. **After conv1 and pool**:\n",
    "    - **Convolution**: The output from conv1 will have the shape (1, 32, 32, 32) (1 batch, 32 channels, 32 height, 32 width) because we have 32 filters and the padding is set to 1, which keeps the size the same.\n",
    "    \n",
    "    - **Pooling**: After applying `MaxPool2d`(2, 2), the height and width are halved, so the output shape becomes (1, 32, 16, 16).\n",
    "\n",
    "3. **After conv2 and pool**:\n",
    "    - **Convolution**: The output from conv2 will have the shape (1, 64, 16, 16) (1 batch, 64 channels).\n",
    "    \n",
    "    - **Pooling**: After pooling, the size will again be halved, resulting in (1, 64, 8, 8).\n",
    "\n",
    "4. **After flatten**: The output is reshaped to (-1, 64 * 8 * 8) which is (-1, 4096). The -1 allows PyTorch to infer the batch size, so it becomes (1, 4096).\n",
    "\n",
    "5. **After fc1**: The output shape is (1, 128) since the first fully connected layer has 128 outputs.\n",
    "6. **After fc2**: Finally, the output shape is (1, num_classes), which in this case will be (1, 10) if you keep the default num_classes as 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple CNN Model with prints after each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "After conv1 and pool: torch.Size([1, 32, 16, 16])\n",
      "After conv2 and pool: torch.Size([1, 64, 8, 8])\n",
      "After flatten: torch.Size([1, 4096])\n",
      "After fc1: torch.Size([1, 128])\n",
      "After fc2: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classses=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\", x.shape)\n",
    "\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        print(\"After conv1:\", x.shape)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        print(\"After Pool1:\", x.shape)\n",
    "\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        print(\"After conv2:\", x.shape)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        print(\"After Pool2:\", x.shape)\n",
    "\n",
    "        x = x.view(-1, 64*8*8) # flatten\n",
    "        print('After Flatten:', x.shape)\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        print('After fc1:', x.shape)\n",
    "\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        print('After fc2:', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN with BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is BatchNorm**?\n",
    "Batch Normalization (often abbreviated as BatchNorm) is a technique widely used in deep learning to improve the training of neural networks, particularly convolutional neural networks (CNNs). Below is a comprehensive overview of Batch Normalization, covering why it should be used, its formula, when to use it, and other important points.\n",
    "\n",
    "#### **Why Use Batch Normalization**?\n",
    "- **1. Stabilizes Learning**: Batch Normalization reduces internal covariate shift, which is the change in the distribution of network activations due to the weights of previous layers.   \n",
    "By normalizing the inputs to each layer, BatchNorm stabilizes learning dynamics.\n",
    "\n",
    "- **2. Accelerates Training**: By normalizing each mini-batch, BatchNorm allows for larger learning rates, which can lead to faster convergence. This means you can train models more quickly and efficiently.\n",
    "\n",
    "- **3. Reduces Sensitivity to Initialization**: Networks with BatchNorm become less sensitive to the initial values of the weights, making it easier to train neural networks successfully.\n",
    "\n",
    "- **4. Acts as a Regularizer**: Batch Normalization can have a slight regularizing effect, reducing the need for other regularization techniques like dropout in some cases.\n",
    "\n",
    "- **5. Improves Performance**: Many researchers have found that using Batch Normalization leads to higher overall performance in terms of accuracy, especially in deeper networks.\n",
    "\n",
    "#### **Formula**\n",
    "The Batch Normalization layer normalizes the input of each layer as follows:\n",
    "\n",
    "For a given mini-batch \n",
    "B containing m examples, with each example having x_i​:\n",
    "- **1. Compute the mean μB and variance σ2B of the mini-batch**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mean and variance in BN](<../../pics/Batchnorm.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2. Normalize the batch**:\n",
    "\n",
    "![Normalize the batch](<../../pics/normalize_batch.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ϵ is a small constant added for numerical stability.\n",
    "\n",
    "- **3. Scale and shift the normalized output**:\n",
    "\n",
    "![scale_shift](<../../pics/scale_shift.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `γ` and `β` are learnable parameters (**scale and shift**) that enable the network to represent the original input data distribution if needed.\n",
    "\n",
    "#### **When to Use Batch Normalization**\n",
    "- **1. After Convolutional Layers**: It is commonly placed after convolutional and fully connected layers but before the activation function (e.g., ReLU).\n",
    "\n",
    "- **2. In Deep Networks**: Especially useful in very deep networks where gradients can vanish or explode.\n",
    "\n",
    "- **3. In Transfer Learning**: When using pre-trained models, BatchNorm can help in fine-tuning the model effectively.\n",
    "\n",
    "- **4. In CNNs for Vision Tasks**: Typically beneficial in tasks like image classification, object detection, and segmentation tasks involving CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve your `SimpleCNN` code with Batch Normalization and multiple pooling strategies, I'll modify it as follows:\n",
    "\n",
    "- **1. Batch Normalization**: Adding batch normalization after each convolutional layer helps stabilize and accelerate training.\n",
    "- **2. Pooling Variants**: Using both Max Pooling and Average Pooling can help the model capture different aspects of spatial features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define custom CNN class\n",
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.avgpool = nn.AvgPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)  # Adjusted input size for pooling layers\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First conv layer with batchnorm and max pooling\n",
    "        x = self.maxpool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Second conv layer with batchnorm and average pooling\n",
    "        x = self.avgpool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loading pre-trained model (ResNet-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for loading pre-trained model (ResNet-18)\n",
    "def load_resnet18(num_classes=10):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper Classes: `AverageMeter` class for tracking loss and other metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.sum / self.count if self.count > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function for visualize a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, labels, classes, normalize=True):\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        ax.set_title(classes[labels[i]])\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasform and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced preprocessing and data augmentation\n",
    "transform_train = T.Compose([T.RandomHorizontalFlip(),\n",
    "                             T.RandomRotation(10),\n",
    "                             T.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "                             T.ToTensor(),\n",
    "                             T.Normalize((0.5, 0.5, 0.5), \n",
    "                                         (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_val = T.Compose([T.ToTensor(),\n",
    "                           T.Normalize((0.5, 0.5, 0.5), \n",
    "                                       (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform_train, download=True)\n",
    "val_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform_val, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "classes = train_dataset.classes\n",
    "plot_images(batch[0], batch[1], classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model & Loss_fn & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (custom CNN or ResNet-18)\n",
    "model_type = \"custom\"  # change to \"resnet\" for ResNet-18\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if model_type == \"custom\":\n",
    "    model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "    summary(model, (3, 32, 32))\n",
    "else:\n",
    "    model = load_resnet18(num_classes=num_classes).to(device)\n",
    "    summary(model, (3, 32, 32))\n",
    "\n",
    "\n",
    "# Define criterion, optimizer, and metrics\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch, accuracy_metric):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_metric.reset()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Training]\", leave=False)\n",
    "    \n",
    "    for X_batch, y_batch in progress_bar:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss and accuracy\n",
    "        loss_meter.update(loss.item(), X_batch.size(0))\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracy_metric.update(preds, y_batch)\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss_meter.avg, accuracy=accuracy_metric.compute().item())\n",
    "        \n",
    "    avg_loss = loss_meter.avg\n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    \n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, epoch, accuracy_metric):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_metric.reset()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Validation]\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Update loss and accuracy\n",
    "            loss_meter.update(loss.item(), X_batch.size(0))\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            accuracy_metric.update(preds, y_batch)\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss_meter.avg)\n",
    "        \n",
    "    avg_loss = loss_meter.avg\n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    \n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard  \n",
    "writer = SummaryWriter()  \n",
    "\n",
    "# Training loop  \n",
    "num_epochs = 20  \n",
    "best_val_acc = 0.0  \n",
    "for epoch in range(num_epochs):  \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, train_accuracy)  \n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device, epoch, val_accuracy)  \n",
    "\n",
    "    # Log metrics to TensorBoard  \n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)  \n",
    "    writer.add_scalar('Accuracy/Train', train_acc, epoch)  \n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)  \n",
    "    writer.add_scalar('Accuracy/Validation', val_acc, epoch)  \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, \"  \n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")  \n",
    "\n",
    "    # Save best model  \n",
    "    if val_acc > best_val_acc:  \n",
    "        best_val_acc = val_acc  \n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  \n",
    "        print(f\"Best model saved at epoch {epoch+1} with validation accuracy: {best_val_acc:.4f}\")  \n",
    "\n",
    "# Close TensorBoard writer  \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracy\n",
    "def plot_metrics(metric_values, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(metric_values, label=f\"{ylabel}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Data visualization function\n",
    "def show_sample_predictions(model, dataloader, class_names, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_batch, y_batch = next(iter(dataloader))\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i in range(8):\n",
    "            plt.subplot(2, 4, i + 1)\n",
    "            plt.imshow(np.transpose(X_batch[i].cpu().numpy(), (1, 2, 0)) * 0.5 + 0.5)  # Un-normalize for display\n",
    "            plt.title(f\"True: {class_names[y_batch[i]]}, Pred: {class_names[preds[i]]}\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Example usage: show predictions for a batch of validation data\n",
    "class_names = train_dataset.classes  # CIFAR-10 class names\n",
    "show_sample_predictions(model, val_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard \n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
