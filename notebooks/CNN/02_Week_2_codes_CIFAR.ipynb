{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebrahim/miniconda3/envs/pytorch23/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN class\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Shape Explanation**\n",
    "\n",
    "1. **Input Shape**: If the input is a single image of size 32x32 with 3 color channels, the shape would be (1, 3, 32, 32).\n",
    "\n",
    "2. **After conv1 and pool**:\n",
    "    - **Convolution**: The output from conv1 will have the shape (1, 32, 32, 32) (1 batch, 32 channels, 32 height, 32 width) because we have 32 filters and the padding is set to 1, which keeps the size the same.\n",
    "    \n",
    "    - **Pooling**: After applying `MaxPool2d`(2, 2), the height and width are halved, so the output shape becomes (1, 32, 16, 16).\n",
    "\n",
    "3. **After conv2 and pool**:\n",
    "    - **Convolution**: The output from conv2 will have the shape (1, 64, 16, 16) (1 batch, 64 channels).\n",
    "    \n",
    "    - **Pooling**: After pooling, the size will again be halved, resulting in (1, 64, 8, 8).\n",
    "\n",
    "4. **After flatten**: The output is reshaped to (-1, 64 * 8 * 8) which is (-1, 4096). The -1 allows PyTorch to infer the batch size, so it becomes (1, 4096).\n",
    "\n",
    "5. **After fc1**: The output shape is (1, 128) since the first fully connected layer has 128 outputs.\n",
    "6. **After fc2**: Finally, the output shape is (1, num_classes), which in this case will be (1, 10) if you keep the default num_classes as 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "After conv1 and pool: torch.Size([1, 32, 16, 16])\n",
      "After conv2 and pool: torch.Size([1, 64, 8, 8])\n",
      "After flatten: torch.Size([1, 4096])\n",
      "After fc1: torch.Size([1, 128])\n",
      "After fc2: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):  \n",
    "    def __init__(self, num_classes=10):  \n",
    "        super(SimpleCNN, self).__init__()  # Fixed a typo in super call  \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  \n",
    "        self.fc2 = nn.Linear(128, num_classes)  \n",
    "\n",
    "    def forward(self, x):  \n",
    "        print(\"Input shape:\", x.shape) \n",
    "        x = self.pool(torch.relu(self.conv1(x)))  \n",
    "        print(\"After conv1 and pool:\", x.shape)  \n",
    "\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  \n",
    "        print(\"After conv2 and pool:\", x.shape)  \n",
    "\n",
    "        x = x.view(-1, 64 * 8 * 8)  # flatten  \n",
    "        print(\"After flatten:\", x.shape)  \n",
    "\n",
    "        x = torch.relu(self.fc1(x))  \n",
    "        print(\"After fc1:\", x.shape) \n",
    "\n",
    "        x = torch.relu(self.fc2(x))  \n",
    "        print(\"After fc2:\", x.shape)  \n",
    "\n",
    "        return x  \n",
    "\n",
    "# Example usage  \n",
    "model = SimpleCNN()  \n",
    "input_tensor = torch.randn(1, 3, 32, 32)  # Batch size of 1, 3 color channels, 32x32 image  \n",
    "output = model(input_tensor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for loading pre-trained model (ResNet-18)\n",
    "def load_resnet18(num_classes=10):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper Classes: `AverageMeter` class for tracking loss and other metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.sum / self.count if self.count > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasform and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced preprocessing and data augmentation\n",
    "transform_train = T.Compose([T.RandomHorizontalFlip(),\n",
    "                             T.RandomRotation(10),\n",
    "                             T.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "                             T.ToTensor(),\n",
    "                             T.Normalize((0.5, 0.5, 0.5), \n",
    "                                         (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_val = T.Compose([T.ToTensor(),\n",
    "                           T.Normalize((0.5, 0.5, 0.5), \n",
    "                                       (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform_train, download=True)\n",
    "val_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform_val, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (custom CNN or ResNet-18)\n",
    "model_type = \"custom\"  # change to \"resnet\" for ResNet-18\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if model_type == \"custom\":\n",
    "    model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "    summary(model, (3, 32, 32))\n",
    "else:\n",
    "    model = load_resnet18(num_classes=num_classes).to(device)\n",
    "    summary(model, (3, 32, 32))\n",
    "\n",
    "\n",
    "# Define criterion, optimizer, and metrics\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch, accuracy_metric):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_metric.reset()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Training]\", leave=False)\n",
    "    \n",
    "    for X_batch, y_batch in progress_bar:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss and accuracy\n",
    "        loss_meter.update(loss.item(), X_batch.size(0))\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracy_metric.update(preds, y_batch)\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss_meter.avg, accuracy=accuracy_metric.compute().item())\n",
    "        \n",
    "    avg_loss = loss_meter.avg\n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    \n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, epoch, accuracy_metric):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_metric.reset()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Validation]\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Update loss and accuracy\n",
    "            loss_meter.update(loss.item(), X_batch.size(0))\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            accuracy_metric.update(preds, y_batch)\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss_meter.avg)\n",
    "        \n",
    "    avg_loss = loss_meter.avg\n",
    "    avg_accuracy = accuracy_metric.compute().item()\n",
    "    \n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard  \n",
    "writer = SummaryWriter()  \n",
    "\n",
    "# Training loop  \n",
    "num_epochs = 20  \n",
    "best_val_acc = 0.0  \n",
    "for epoch in range(num_epochs):  \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, train_accuracy)  \n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device, epoch, val_accuracy)  \n",
    "\n",
    "    # Log metrics to TensorBoard  \n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)  \n",
    "    writer.add_scalar('Accuracy/Train', train_acc, epoch)  \n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)  \n",
    "    writer.add_scalar('Accuracy/Validation', val_acc, epoch)  \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, \"  \n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")  \n",
    "\n",
    "    # Save best model  \n",
    "    if val_acc > best_val_acc:  \n",
    "        best_val_acc = val_acc  \n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  \n",
    "        print(f\"Best model saved at epoch {epoch+1} with validation accuracy: {best_val_acc:.4f}\")  \n",
    "\n",
    "# Close TensorBoard writer  \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracy\n",
    "def plot_metrics(metric_values, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(metric_values, label=f\"{ylabel}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Data visualization function\n",
    "def show_sample_predictions(model, dataloader, class_names, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_batch, y_batch = next(iter(dataloader))\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i in range(8):\n",
    "            plt.subplot(2, 4, i + 1)\n",
    "            plt.imshow(np.transpose(X_batch[i].cpu().numpy(), (1, 2, 0)) * 0.5 + 0.5)  # Un-normalize for display\n",
    "            plt.title(f\"True: {class_names[y_batch[i]]}, Pred: {class_names[preds[i]]}\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Example usage: show predictions for a batch of validation data\n",
    "class_names = train_dataset.classes  # CIFAR-10 class names\n",
    "show_sample_predictions(model, val_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard \n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
